# Diabetes-Prediction-Using-Machine-Learning-BRFSS-2015- in R
This project builds and compares several machine learning models to predict diabetes using the BRFSS 2015 Health Indicators dataset.
The goal is to evaluate how well different algorithms can classify individuals as diabetic or non-diabetic based on health, lifestyle, and demographic features.

The models evaluated include:

✔ Logistic Regression

✔ Random Forest

✔ XGBoost

✔ Super-Fast Linear SVM (LiblineaR)

✔ LASSO Logistic Regression (GLMNET)

All models are assessed using AUC (Area Under the ROC Curve) for fair comparison
# Project Structure
diabetes-ml-prediction/
│
├── data/
│     └── diabetes_binary_health_indicators_BRFSS2015.csv   (optional)
│
├── plots/
│     └── roc_all_models.png
│
├── diabetes-ml-models.R
├── README.md
├── LICENSE
└── .gitignore

# Required R Packages
install.packages(c(
  "tidyverse","caret","pROC","randomForest","xgboost",
  "e1071","glmnet","corrplot","MLmetrics","ranger",
  "doParallel","kernlab","LiblineaR"
))
# Dataset
The project uses the "diabetes_binary_health_indicators_BRFSS2015.csv" dataset. Download it from this link 
https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset
# How to Run This Project
1. Clone the repository
git clone https://github.com/yourusername/diabetes-ml-prediction.git
cd diabetes-ml-prediction
2. Open R or RStudio
3. Install required packages (sell section above)
4. Place dataset in the /data directory
5. Run the script
source("diabetes-ml-models.R")
  The script will:

preprocess the dataset

train all five ML models

compute AUC for each model

generate ROC curves

save the final comparison plot
# Model Performance (AUC Comparison)

Below are the performance results from the final model run:
| Model                  | AUC        |
| ---------------------- | ---------- |
| **XGBoost**            | **0.8298** |
| LASSO Logistic         | 0.8223     |
| Linear SVM (LiblineaR) | 0.8222     |
| Logistic Regression    | 0.8222     |
| Random Forest          | 0.8170     |

# ROC Curve Visualization

A combined ROC curve for all models is generated by the script.

Saved to:
plots/roc_all_models.png
# Methods Overview
Preprocessing

Center + scale numeric predictors

Stratified train/test split (80/20)
Models Trained
| Model                  | Description                                    |
| ---------------------- | ---------------------------------------------- |
| Logistic Regression    | Baseline linear classifier                     |
| Random Forest (ranger) | Fast tree ensemble                             |
| XGBoost                | Gradient boosting, usually top performer       |
| LiblineaR SVM          | Extremely fast linear SVM/logistic formulation |
| LASSO (GLMNET)         | Feature selection + regularized logistic       |

# Evaluation Metric

ROC Curve

Area Under the Curve (AUC)
# License

This project is licensed under the MIT License.
# Acknowledgments

Dataset:
CDC Behavioral Risk Factor Surveillance System (BRFSS)
Kaggle Dataset Preparation: Alex Teboul


